{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling and reorganizing heating/cooling demand data.\n",
    "\n",
    "This script reads, normalises, and reorganises the raw ArchetypeBuildingModel output\n",
    "for Mopo WP5.\n",
    "Depending on the exact needs, these scripts might need quite a bit of tinkering later on as well, but let's do something for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Julia environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Julia environment setup\n",
    "\n",
    "using Pkg\n",
    "Pkg.activate(@__DIR__)\n",
    "Pkg.instantiate()\n",
    "\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Dates\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read, reorganise, and normalise the raw ABM demand data.\n",
    "\n",
    "Essentially, the demand profiles here are normalised using their yearly sums.\n",
    "Whether this is the way WP5 eventually wants this data is still a bit unclear,\n",
    "but at least scaling and rescaling should be easy based on these.\n",
    "\n",
    "Furthermore, scaled normalised values are calculated based on the average yearly\n",
    "demands across all available weather years.\n",
    "This approach aims to preserve variability between weather years, while still allowing them to be scaled to match future projections.\n",
    "\n",
    "Essentially, we're sort of emulating what Hotmaps projections do, using average HDD and CDD from 2002-2012 as the basis for their heating and cooling demand calculations.\n",
    "However, actual HDD and CDD-based scaling suffers from data availability issues outside EU like so many other data sources.\n",
    "This is not perfect, but hopefully it will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Config for normalising the raw data\n",
    "\n",
    "years = [1995, 2008, 2009, 2012, 2015]\n",
    "dem_paths = [\n",
    "    year => \"input-data/abm-raw-data/ideal_demands_$(year).csv\"\n",
    "    for year in years\n",
    "];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read, organise, and normalise demands data.\n",
    "\n",
    "# Read and organise the data.\n",
    "dem_cols = [:timestamp, :weather_year, :country, :category, :demand, :value]\n",
    "dem_data = DataFrame()\n",
    "for (year, path) in dem_paths\n",
    "    df = stack(DataFrame(CSV.File(path; header=[1,2])))\n",
    "    s = split.(df[!, :variable], '_')\n",
    "    df[!, :country] = String.(getindex.(s, 1))\n",
    "    df[!, :category] = String.(getindex.(s, 2))\n",
    "    df[!, :demand] = String.(getindex.(s, 6))\n",
    "    df[!, :weather_year] .= year\n",
    "    rename!(\n",
    "        df,\n",
    "        :building_archetype_building_process => :timestamp,\n",
    "    )\n",
    "    append!(dem_data, df[!, dem_cols])\n",
    "end\n",
    "\n",
    "# Add normalised data\n",
    "dem_sums = combine( # Calculate yearly sums\n",
    "    groupby(\n",
    "        dem_data,\n",
    "        dem_cols[2:end-1] # Skip timestamp and value.\n",
    "    ),\n",
    "    :value => sum\n",
    ")\n",
    "dem_sums_means = combine( # Calculate mean of yearly sums\n",
    "    groupby(\n",
    "        dem_sums,\n",
    "        dem_cols[3:end-1] # Group by :country, :category, and :demand\n",
    "    ),\n",
    "    :value_sum => mean\n",
    ")\n",
    "leftjoin!(dem_data, dem_sums, on=dem_cols[2:end-1])\n",
    "leftjoin!(dem_data, dem_sums_means, on=dem_cols[3:end-1])\n",
    "dem_data[!, :value_norm] = dem_data.value ./ dem_data.value_sum\n",
    "dem_data[!, :scaling_factor] = dem_data.value_sum ./ dem_data.value_sum_mean\n",
    "dem_data[!, :value_norm_scaled] = dem_data.value_norm .* dem_data.scaling_factor\n",
    "describe(dem_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check that normalisation worked as intended\n",
    "\n",
    "dem_normalised_sums = combine(\n",
    "    groupby(\n",
    "        dem_data,\n",
    "        dem_cols[2:end-1]\n",
    "    ),\n",
    "    :value_norm => sum\n",
    ")\n",
    "all(dem_normalised_sums.value_norm_sum .â‰ˆ 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch the ratios of peak demand to the yearly demand\n",
    "\n",
    "dem_normalised_peak_demands = combine(\n",
    "    groupby(\n",
    "        dem_data,\n",
    "        [:country, :demand]\n",
    "    ),\n",
    "    :value_norm => maximum\n",
    ")\n",
    "describe(dem_normalised_peak_demands)\n",
    "\n",
    "# These can be used for estimating heat-only boiler capacity later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read, organise, and process Hotmaps scenario data for demand scaling.\n",
    "\n",
    "The next step is to read the Hotmaps scenario data and process it to a format for easy scaling.\n",
    "\n",
    "\n",
    "### Norway and Switzerland missing...\n",
    "\n",
    "Turns out Norway and Switzerland are in fact **not** included in the Hotmaps scenario data,\n",
    "despite their indices showing up in the .csv files.\n",
    "They have `missing` data, so no actual numbers for the heating and cooling demand.\n",
    "Guess I'll have to use neighbouring countries scaled using population as the basis again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure reading Hotmaps data\n",
    "\n",
    "hm_current_path = \"input-data/scen_current_building_demand/data/scen_current_building_demand.csv\"\n",
    "hm_ambitious_path = \"input-data/scen_ambitious_building_demand/data/scen_ambitious_building_demand.csv\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read and organise the Hotmaps data\n",
    "\n",
    "hm_current_data_raw = dropmissing!(DataFrame(CSV.File(hm_current_path)))\n",
    "hm_ambitious_data_raw = dropmissing!(DataFrame(CSV.File(hm_ambitious_path)))\n",
    "hm_data = vcat(hm_current_data_raw, hm_ambitious_data_raw)\n",
    "rename!( # Column renaming for dataset compatibility.\n",
    "    hm_data,\n",
    "    Dict(\n",
    "        :NUTS0_code => :country,\n",
    "        :Year => :scenario_year,\n",
    "        :Value => :scenario_value,\n",
    "        :Unit => :unit, \n",
    "    )\n",
    ")\n",
    "replace!( # Country renaming to align datasets.\n",
    "    hm_data[!, :country],\n",
    "    \"GB\" => \"UK\",\n",
    "    \"GR\" => \"EL\"\n",
    ")\n",
    "supertype_to_category_map = Dict( # Map supertype to category\n",
    "    \"Residential\" => \"res\",\n",
    "    \"Nonresidential_private\" => \"nonres\",\n",
    "    \"Nonresidential_public\" => \"nonres\"\n",
    ")\n",
    "hm_data[!, :category] = map(\n",
    "    x -> get(supertype_to_category_map, x, missing),\n",
    "    hm_data[!, :Supertype]\n",
    ")\n",
    "type_to_demand_map = Dict( # Map types to demands, drop \"auxiliary energy demand\"\n",
    "    \"space heating\" => \"heating\",\n",
    "    \"cooling\" => \"cooling\",\n",
    "    \"hot water\" => \"DHW\"\n",
    ")\n",
    "hm_data[!, :demand] = map(\n",
    "    x -> get(type_to_demand_map, x, missing),\n",
    "    hm_data[!, :Type]\n",
    ")\n",
    "dropmissing!(hm_data)\n",
    "\n",
    "\n",
    "## Add missing data for Norway and Switzerland based on Sweden and Austria respectively.\n",
    "\n",
    "extrapolation_mappings = Dict( # Map Norway and Switzerland to existing data with population-based coefficients\n",
    "    \"NO\" => (\"SE\", 0.52),\n",
    "    \"CH\" => (\"AT\", 0.97)\n",
    ")\n",
    "for (c1, (c2, coeff)) in extrapolation_mappings\n",
    "    df = filter(r -> r.country == c2, hm_data)\n",
    "    df.country .= c1\n",
    "    df[!, :scenario_value] .*= coeff\n",
    "    append!(hm_data, df)\n",
    "end\n",
    "describe(hm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate total distributed heating demands across the desired dims.\n",
    "\n",
    "agg_cols = [:Scenario, :scenario_year, :country, :category, :demand, :unit]\n",
    "hm_sums = combine(\n",
    "    groupby(\n",
    "        filter(r -> r.Fuel != \"District heating\", hm_data),\n",
    "        agg_cols\n",
    "    ),\n",
    "    :scenario_value => sum\n",
    ")\n",
    "hm_sums.Fuel .= \"distributed heating\"\n",
    "\n",
    "# Include district heating rows\n",
    "dh_sums = combine(\n",
    "    groupby(\n",
    "        filter(r -> r.Fuel == \"District heating\", hm_data),\n",
    "        agg_cols\n",
    "    ),\n",
    "    :scenario_value => sum\n",
    ")\n",
    "dh_sums.Fuel .= \"district heating\"\n",
    "hm_sums = vcat(hm_sums, dh_sums)\n",
    "describe(hm_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check heating-to-DHW ratios\n",
    "\n",
    "heating_to_dhw = filter(row -> row.demand == \"heating\", hm_sums)\n",
    "dhw = filter(row -> row.demand == \"DHW\", hm_sums)\n",
    "heating_to_dhw.scenario_value_sum ./= dhw.scenario_value_sum\n",
    "filter(row ->  row.country == \"FI\", heating_to_dhw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check res-to-nonres ratios\n",
    "\n",
    "res_to_nonres = filter(row -> row.category == \"res\", hm_sums)\n",
    "nonres = filter(row -> row.category == \"nonres\", hm_sums)\n",
    "res_to_nonres.scenario_value_sum ./= nonres.scenario_value_sum\n",
    "filter(row ->  row.country == \"FI\", res_to_nonres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine heat pump COPs\n",
    "\n",
    "The Hotmaps data has separate values for `Electricity` and `Ambient Heat` as the `Fuel` for heat pumps. Let's see how these assumptions vary between countries and end-uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Examine the heat pump COPs based on their electricity and ambient heat consumption\n",
    "\n",
    "df = hm_data[hm_data.Technology .== \"heat pumps\", :]\n",
    "df = unstack(df, :Fuel, :scenario_value)\n",
    "df = df[df.Electricity .> 0, :]\n",
    "df.COP .= (df.Electricity + df[!, Symbol(\"ambient heat\")]) ./ df.Electricity\n",
    "#sort!(df, :COP; rev=true)\n",
    "describe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that's a bit alarming: The mean COP in the Hotmaps data is above six, which seems pretty unrealistic. Furthermore, the maximum COP is infeasibly high, and weirdly seems to occur mostly for DHW.\n",
    "\n",
    "Therefore, there's a risk that the modelled heat pump capacity is not enough to cover the demand in certain countries if I use the `Electricity` fuel as the basis for the assumed existing capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check space heating and DHW separately:\n",
    "\n",
    "df_cop_demand = unstack(df, :demand, :COP)\n",
    "describe(df_cop_demand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, the space heating COPs are lower than DHW COPs, which shouldn't be the case. Not really sure what's going on here with the Hotmaps data. Ultimately, it might be necessary to estimate the existing heat pump capacity based on the total and the assumed technology parameter COP, but we'll see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate generation capacities\n",
    "\n",
    "We'll have to estimate the technology capacities based on the yearly demands and the estimated demand peak ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate estimated peak capacities.\n",
    "\n",
    "hm_capacity_data = leftjoin( # Combine estimated peak demand ratio data with yearly demands.\n",
    "    hm_data,\n",
    "    dem_normalised_peak_demands;\n",
    "    on=[:country, :demand],\n",
    ")\n",
    "rename!(hm_capacity_data, :value_norm_maximum => :peak_to_yearly_demand_ratios_GW_GWh)\n",
    "hm_capacity_data.capacity_MW = ( # Calculate the estimated capacity in MW\n",
    "    hm_capacity_data.scenario_value\n",
    "    .* hm_capacity_data.peak_to_yearly_demand_ratios_GW_GWh\n",
    "    .* 1000\n",
    ")\n",
    "describe(hm_capacity_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technology mapping\n",
    "\n",
    "Map the estimated peak capacities to the desired technologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Figure out heating system mappings from Hotmaps to the desired techs.\n",
    "\n",
    "heat_techs = unique(hm_data.Technology)\n",
    "gas_boiler = filter(x -> contains(lowercase(x), \"gas boiler\"), heat_techs)\n",
    "bio_boiler = filter(x -> contains(lowercase(x), \"biomass\"), heat_techs)\n",
    "oil_boiler = filter(x -> contains(lowercase(x), \"oil boiler\"), heat_techs)\n",
    "air_heatpump = filter(x -> contains(lowercase(x), \"heat pump\"), heat_techs) # Data doesn't distinguish between different heat pumps.\n",
    "ground_heatpump = filter(x -> contains(lowercase(x), \"heat pump\"), heat_techs) # Data doesn't distinguish between different heat pumps.\n",
    "solar_heating = filter(x -> contains(lowercase(x), \"solar\"), heat_techs)\n",
    "electric_heating = filter(x -> contains(lowercase(x), \"electric\"), heat_techs)\n",
    "district_heating = filter(x -> contains(lowercase(x), \"district heating\"), heat_techs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map hm_data technologies to the desired heating techs.\n",
    "\n",
    "distributed_tech_mapping = Dict( # (Set of technologies, assumed share)\n",
    "    \"gas-boiler\" => (gas_boiler, 1.0),\n",
    "    \"bio-boiler\" => (bio_boiler, 1.0),\n",
    "    \"oil-boiler\" => (oil_boiler, 1.0),\n",
    "    \"air-heatpump\" => (air_heatpump, 0.7), # Assumed 70% market share for A2WHPs\n",
    "    \"ground-heatpump\" => (ground_heatpump, 0.3), # Assumed 30% market share for G2WHPs\n",
    "    \"solar-heating\" => (solar_heating, 1.0),\n",
    "    \"electric-heating\" => (electric_heating, 1.0),\n",
    "    \"district-heating\" => (district_heating, 1.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the capacities together\n",
    "\n",
    "rename_cols = Dict(\n",
    "    :Scenario => :scenario,\n",
    "    :scenario_year => :scenario_year,\n",
    "    :country => :country,\n",
    "    :category => :building_category,\n",
    "    :output_technology => :technology,\n",
    "    :demand => :demand,\n",
    "    :weighted_capacity_MW => :capacity,\n",
    "    :capacity_unit => :unit,\n",
    "    :demand_category => :demand_category,\n",
    ")\n",
    "heating_capacity_data = DataFrame()\n",
    "for (name, (techs, weight)) in distributed_tech_mapping\n",
    "    # Filter relevant technologies.\n",
    "    df = filter(\n",
    "        r -> r.Technology in techs && r.Fuel != \"ambient heat\", # Heat pumps have two fuel rows, omitting \"ambient heat\" since it's likely not what Alvaro wants.\n",
    "        hm_capacity_data\n",
    "    )\n",
    "    if isempty(df) # Skip the rest of the loop if df is empty\n",
    "        continue\n",
    "    end\n",
    "    # Calculate the weighted capacities\n",
    "    df.output_technology .= name\n",
    "    df.weighted_capacity_MW .= df.capacity_MW .* weight\n",
    "    df.capacity_unit .= \"MW\"\n",
    "    df.demand_category .= (name == \"district-heating\" ? \"district heating\" : \"distributed heating\")\n",
    "    # Final formatting\n",
    "    df = df[!, collect(keys(rename_cols))] # Drop unused columns\n",
    "    rename!(df, rename_cols)\n",
    "    country_cols = Symbol.(unique(df.country))\n",
    "    df = stack( # Avoid nonresidential private vs nonresidential public duplicate row hassle by unstack-stack summing.\n",
    "        unstack(\n",
    "            df,\n",
    "            :country,\n",
    "            :capacity;\n",
    "            combine=sum\n",
    "        ),\n",
    "        country_cols;\n",
    "        variable_name=:country,\n",
    "        value_name=:capacity\n",
    "    )\n",
    "    append!(heating_capacity_data, df)\n",
    "end\n",
    "describe(heating_capacity_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine datasets, calculate scaled demand, and export desired timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export timeseries\n",
    "\n",
    "# Export config\n",
    "years = [1995, 2008, 2009, 2012, 2015]\n",
    "dgts = 4 # Number of digits when rounding exports\n",
    "categories = [\"res\", \"nonres\"]\n",
    "demands = [\"heating\", \"cooling\", \"DHW\"]\n",
    "index_cols = [:timestamp, :country]\n",
    "\n",
    "# Export demand timeseries csvs\n",
    "for cat in categories\n",
    "    for dem in demands\n",
    "        for year in years\n",
    "            df = filter(\n",
    "                r -> r.weather_year == year && r.category == cat && r.demand == dem,\n",
    "                dem_data\n",
    "            )\n",
    "            df = df[!, vcat(index_cols, :value_norm_scaled)]\n",
    "            df.value_norm_scaled = round.(df.value_norm_scaled .* 1000; digits=dgts) # Scaling to MW/GWh\n",
    "            df = sort!(unstack(df[!, vcat(index_cols, :value_norm_scaled)], :country, :value_norm_scaled))\n",
    "            CSV.write(\"output/demand-timeseries/$(dem)_$(cat)_wy$(year)_normalised_MW_GWh.csv\", df)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export country-wise peak-to-yearly-demand ratios\n",
    "\n",
    "# Config\n",
    "dgts = 4 # Digits for rounding peak demands\n",
    "\n",
    "# Export\n",
    "export_df = sort(dem_normalised_peak_demands)\n",
    "export_df.value_norm_maximum = round.(\n",
    "    export_df.value_norm_maximum .* 1000; digits=dgts\n",
    ") # Round and convert to MW/GWh\n",
    "export_df.unit .= \"MW/GWh\"\n",
    "export_df = unstack(export_df, :country, :value_norm_maximum)\n",
    "CSV.write(\n",
    "    \"output/peak_to_yearly_demand_ratios_MW_GWh.csv\",\n",
    "    export_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export scenario demands\n",
    "\n",
    "# Config\n",
    "dgts = 2 # Number of digits when rounding exports.\n",
    "\n",
    "# Export table\n",
    "hm_export = rename(\n",
    "    hm_sums,\n",
    "    Dict(\n",
    "        :Scenario => :scenario,\n",
    "        :category => :building_category,\n",
    "        :Fuel => :demand_category,\n",
    "    )\n",
    ")\n",
    "hm_export = sort(hm_export[!, [:scenario, :scenario_year, :country, :building_category, :demand_category, :demand, :unit, :scenario_value_sum]])\n",
    "hm_export.scenario_value_sum = round.(hm_export.scenario_value_sum; digits=dgts)\n",
    "hm_export = unstack(hm_export, :country, :scenario_value_sum)\n",
    "CSV.write(\"output/scenario_total_yearly_demands_GWh.csv\", hm_export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export assumed existing capacity data\n",
    "\n",
    "# Config\n",
    "dgts = 2 # Number of digits when rounding exports.\n",
    "export_cols = [\n",
    "    :scenario,\n",
    "    :scenario_year,\n",
    "    :country,\n",
    "    :building_category,\n",
    "    :demand_category,\n",
    "    :demand,\n",
    "    :technology,\n",
    "    :unit,\n",
    "    :capacity\n",
    "]\n",
    "\n",
    "# Export table\n",
    "capacity_export = heating_capacity_data[:, export_cols]\n",
    "capacity_export.capacity = round.(capacity_export.capacity; digits=dgts)\n",
    "capacity_export = sort!(unstack(\n",
    "    capacity_export,\n",
    "    :country,\n",
    "    :capacity,\n",
    "    combine=sum # Avoid nonresidential private vs nonresidential public duplicate row hassle.\n",
    "))\n",
    "CSV.write(\"output/scenario_estimated_existing_capacities_MW.csv\", capacity_export)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot diagnostics to see how the data looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scale demands based on select scenario year.\n",
    "\n",
    "scenario_year = 2025 # Select scenario year\n",
    "scenario = \"current\" # Select scenario\n",
    "\n",
    "scen_data = filter( # Filter the desired scenario and year\n",
    "    r -> r.scenario_year == scenario_year && r.Scenario == scenario,\n",
    "    hm_sums\n",
    ")\n",
    "scen_data = combine( # Sum \"district heating\" and \"distributed heating\"\n",
    "    groupby(scen_data, [:country, :category, :demand]),\n",
    "    :scenario_value_sum => sum\n",
    ")\n",
    "full_data = leftjoin(dem_data, scen_data, on=[:country, :category, :demand])\n",
    "full_data.final_scaled_value_MW = full_data.value_norm_scaled .* full_data.scenario_value_sum_sum .* 1000\n",
    "describe(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot diagnostics\n",
    "\n",
    "using StatsPlots\n",
    "\n",
    "plot_year = 1995\n",
    "plot_cols = [:timestamp, :category, :final_scaled_value_MW]\n",
    "countries = Set(full_data.country)\n",
    "f = nothing # How many timesteps to plot, `nothing` plots all\n",
    "\n",
    "for c in countries\n",
    "    for dem in demands\n",
    "        df = filter(\n",
    "            r -> r.weather_year == plot_year && r.demand == dem && r.country == c,\n",
    "            full_data\n",
    "        )\n",
    "        df = df[!, plot_cols]\n",
    "        df = unstack(df, :category, :final_scaled_value_MW)\n",
    "        isnothing(f) ? nothing : df = first(df, f)\n",
    "        plt = plot(\n",
    "            df[!, 1],\n",
    "            hcat(df[!, 2], df[!, 3]);\n",
    "            title = \"$(c) $(dem)\",\n",
    "            labels = reshape(names(df)[2:3], 1, 2)\n",
    "        )\n",
    "        display(plt)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot When2Heat data for comparison\n",
    "\n",
    "f = 168\n",
    "w2h_data = DataFrame(CSV.File(\"input-data/when2heat/spaceHeat_2025_hour_country_1995.csv\"))\n",
    "for c in intersect(Set(w2h_data.country), Set(full_data.country))\n",
    "    # ABM data\n",
    "    df = filter(\n",
    "        r -> r.weather_year == 1995 && r.demand == \"heating\" && r.country == c,\n",
    "        full_data\n",
    "    )\n",
    "    df = df[!, plot_cols]\n",
    "    df = combine(\n",
    "        groupby(df, :timestamp),\n",
    "        :final_scaled_value_MW => sum\n",
    "    )\n",
    "    df.final_scaled_value_MW_sum ./= maximum(df.final_scaled_value_MW_sum)\n",
    "    isnothing(f) ? nothing : df = first(df, f)\n",
    "    plt = plot(\n",
    "        df[!, 1],\n",
    "        df[!, 2];\n",
    "        title = \"$(c)\",\n",
    "        label = \"abm\"\n",
    "    )\n",
    "\n",
    "    # When2Heat data\n",
    "    df2 = filter(r -> r.country == c, w2h_data)\n",
    "    isnothing(f) ? nothing : df2 = first(df2, f)\n",
    "    plot!(\n",
    "        plt,\n",
    "        df[!, 1],\n",
    "        df2[!, 3];\n",
    "        label = \"w2h\"\n",
    "    )\n",
    "    display(plt)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not great, not terrible.**\n",
    "\n",
    "There's a pretty significant difference between the heating demands from\n",
    "ArchetypeBuildingModel and the when2heat datasets.\n",
    "In a sense, it's not that surprising, as the they use wildly different\n",
    "approaches for calculating the heating demands.\n",
    "\n",
    "Overall, I would still expect when2heat data to be more reliable,\n",
    "since from what I understand it is a heating-degree-day-approach\n",
    "based on actual gas-use measurements from Germany.\n",
    "However, I'm a bit sceptical on how well the when2heat timeseries apply\n",
    "to countries with different heating preferences _(e.g. the Nordics)_.\n",
    "\n",
    "Not sure if ArchetypeBuildingModel really should even be used for\n",
    "something like this, but for now it seems to be what we're stuck with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
